{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\napi_key = 'djvzi2qwau9s1iae317x3sumhi4ovilo'   # Your API key provided by Idealista\\nsecret = 'dExwCHGjb87b'   # Your secred code provided by Idealista\\n\\napi_key = 'z11k3lqpxg3z6zf80628a8745n8sqrdg'   # Your API key provided by Idealista\\n    secret = 'Fem4xrnUfG8N'   # Your secred code provided\\xa0by\\xa0Idealista\""
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\n",
    "    api_key = 'djvzi2qwau9s1iae317x3sumhi4ovilo'   # Your API key provided by Idealista\n",
    "    secret = 'dExwCHGjb87b'   # Your secred code provided by Idealista\n",
    "\n",
    "    api_key = 'z11k3lqpxg3z6zf80628a8745n8sqrdg'   # Your API key provided by Idealista\n",
    "        secret = 'Fem4xrnUfG8N'   # Your secred code provided by Idealista\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search URL: https://api.idealista.com/3.5/es/search?operation=sale&maxItems=50&order=publicationDate&locationId=0-EU-ES-28&propertyType=homes&sort=desc&numPage=%s&maxPrice=850000&minPrice=100000&language=es\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import base64\n",
    "import requests as rq\n",
    "import json\n",
    "\n",
    "# Function to obtain the OAuth token\n",
    "def get_oauth_token():\n",
    "    '''\n",
    "    This function will return our personalised token\n",
    "    '''\n",
    "    api_key = 'z11k3lqpxg3z6zf80628a8745n8sqrdg'   # Replace with your API Key\n",
    "    secret = 'Fem4xrnUfG8N'     # Replace with your Secret Key\n",
    "\n",
    "    message = api_key + \":\" + secret   # Combine the API key and the secret to get our personalised message\n",
    "    auth = \"Basic \" + base64.b64encode(message.encode(\"ascii\")).decode(\"ascii\")   # Encode the message\n",
    "\n",
    "    headers_dic = {\n",
    "        \"Authorization\": auth,\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded;charset=UTF-8\"\n",
    "    }   # Define our headers\n",
    "\n",
    "    params_dic = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"scope\": \"read\"\n",
    "    }   # Define the request params\n",
    "\n",
    "    r = rq.post(\"https://api.idealista.com/oauth/token\",\n",
    "                headers=headers_dic,\n",
    "                params=params_dic)\n",
    "\n",
    "    token = json.loads(r.text)['access_token']   # Obtain the personalised token, as a json\n",
    "\n",
    "    return token\n",
    "\n",
    "# API search parameters\n",
    "base_url = 'https://api.idealista.com/3.5/'  # Base search url\n",
    "country = 'es'  # Search country (es, it, pt)\n",
    "language = 'es'  # Search language (es, it, pt, en, ca)\n",
    "max_items = '50'  # Max items per call, the maximum set by Idealista is 50\n",
    "operation = 'sale'  # Type of operation (sale, rent)\n",
    "property_type = 'homes'  # Type of property (homes, offices, premises, garages, bedrooms)\n",
    "order = 'publicationDate'  # Order by publication date\n",
    "location_id = '0-EU-ES-28' # Idealista location code for Madrid Province\n",
    "sort = 'desc'  # Sort from most recent to oldest\n",
    "bankOffer = 'false'  # If the owner is a bank\n",
    "maxprice = '850000'  # Max price\n",
    "minprice = '100000'  # Min price\n",
    "\n",
    "# Define a function to build the search URL\n",
    "def define_search_url():\n",
    "    '''\n",
    "    This function will create our search URL with the modified filters\n",
    "    '''\n",
    "    url = (\n",
    "        base_url +\n",
    "        country +\n",
    "        '/search?operation=' + operation +\n",
    "        '&maxItems=' + max_items +\n",
    "        '&order=' + order +  # Order by publication date\n",
    "        '&locationId=' + location_id +  # Instead of center+distance\n",
    "        '&propertyType=' + property_type +\n",
    "        '&sort=' + sort +  # Sort in descending order (newest first)\n",
    "        '&numPage=%s' +  # Pagination\n",
    "        '&maxPrice=' + maxprice +\n",
    "        '&minPrice=' + minprice +\n",
    "        '&language=' + language\n",
    "    )\n",
    "\n",
    "    return url\n",
    "\n",
    "# Example usage\n",
    "search_url = define_search_url()\n",
    "print(\"Search URL:\", search_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_api(url):\n",
    "    '''\n",
    "    This function will use the token and url created previously, and return our search results.\n",
    "    '''\n",
    "    token = get_oauth_token()   #  Get the personalised token\n",
    "\n",
    "    headers = {'Content-Type': 'Content-Type: multipart/form-data;',   # Define the search headers\n",
    "               'Authorization' : 'Bearer ' + token}\n",
    "\n",
    "    content = rq.post(url, headers = headers)   # Return the content from the request\n",
    "\n",
    "    result = json.loads(content.text)   # Transform the result as a json file\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we need to give pagination to our search and this is our first search, we will set the pagination as 1\n",
    "pagination = 1 #\n",
    "first_search_url = url %(pagination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.idealista.com/3.5/es/search?operation=sale&maxItems=50&order=publicationDate&locationId=0-EU-ES-28&propertyType=homes&sort=desc&numPage=100&maxPrice=850000&minPrice=100000&language=es\n"
     ]
    }
   ],
   "source": [
    "print(first_search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed to do the search with the paginated url\n",
    "results = search_api(first_search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, we can extract 50 results/page, but there are more pages, so we have to define how many pages there are.\n",
    "\n",
    "total_pages = results['totalPages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    }
   ],
   "source": [
    "print(total_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_df(results):\n",
    "    '''\n",
    "    This function will save the json results as a dataframe and return the resulting dataframe\n",
    "    '''\n",
    "    df = pd.DataFrame.from_dict(results['elementList'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(df, df_tot):\n",
    "    '''\n",
    "    This function will take the main dataframe (df_tot), and concat it with the given individual dataframe,\n",
    "    returning the main dataframe\n",
    "    '''\n",
    "    df_tot= pd.concat([df_tot,df],ignore_index=True)\n",
    "\n",
    "    return df_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed to save the obtained results as a dataframe\n",
    "df = results_to_df(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we still don't have a main dataframe where we can store all the data, we will create an empty dataframe\n",
    "df_tot = pd.DataFrame()\n",
    "df_tot = concat_df(df, df_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = first_search_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.idealista.com/3.5/es/search?operation=sale&maxItems=50&order=publicationDate&locationId=0-EU-ES-28&propertyType=homes&sort=desc&numPage=100&maxPrice=850000&minPrice=100000&language=es\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
     ]
    }
   ],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  propertyCode                                          thumbnail  \\\n",
      "0    107253989  https://img4.idealista.com/blur/WEB_LISTING/0/...   \n",
      "\n",
      "  externalReference  numPhotos floor     price  \\\n",
      "0         INVERSION         50     1  460000.0   \n",
      "\n",
      "                                           priceInfo propertyType operation  \\\n",
      "0  {'price': {'amount': 460000.0, 'currencySuffix...         flat      sale   \n",
      "\n",
      "   size  ... has3DTour  has360  hasStaging                          highlight  \\\n",
      "0  87.0  ...     False    True       False  {'groupDescription': 'Destacado'}   \n",
      "\n",
      "  savedAd notes topNewDevelopment topPlus parkingSpace  newDevelopmentFinished  \n",
      "0      {}    []             False   False          NaN                     NaN  \n",
      "\n",
      "[1 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_tot.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m define_search_url()\n\u001b[0;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m url \u001b[38;5;241m%\u001b[39m(i)   \u001b[38;5;66;03m# Add the pagination to the url\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# Get the search results\u001b[39;00m\n\u001b[0;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m results_to_df(results)   \u001b[38;5;66;03m# Save the results as a dataframe\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df_tot \u001b[38;5;241m=\u001b[39m concat_df(df, df_tot)   \u001b[38;5;66;03m# Concat the results to the main dataframe\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[36], line 12\u001b[0m, in \u001b[0;36msearch_api\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      7\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type: multipart/form-data;\u001b[39m\u001b[38;5;124m'\u001b[39m,   \u001b[38;5;66;03m# Define the search headers\u001b[39;00m\n\u001b[0;32m      8\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m token}\n\u001b[0;32m     10\u001b[0m content \u001b[38;5;241m=\u001b[39m rq\u001b[38;5;241m.\u001b[39mpost(url, headers \u001b[38;5;241m=\u001b[39m headers)   \u001b[38;5;66;03m# Return the content from the request\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# Transform the result as a json file\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# This will loop over all the pages in the search results. It start from 2, because we've already gotten the first page\n",
    "for i in range(pagination+1, total_pages):\n",
    "    url = define_search_url()\n",
    "    url = url %(i)   # Add the pagination to the url\n",
    "    results = search_api(url)   # Get the search results\n",
    "    df = results_to_df(results)   # Save the results as a dataframe\n",
    "    df_tot = concat_df(df, df_tot)   # Concat the results to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we have all our data, we just need to save it as a csv file, we have created the following function for that:\n",
    "\n",
    "file_path = r'C:\\Users\\nicol\\OneDrive\\Documentos\\VSCLocal\\Data\\TFM\\idealista_sale_03_2025_2.csv'\n",
    "\n",
    "def df_to_csv(df):\n",
    "    '''\n",
    "    This function will take a given dataframe and save it as a csv file\n",
    "    '''\n",
    "    df = df.reset_index()   # Reset the index in order to organise the records\n",
    "    df.to_csv(file_path, index=False)   # Save it into a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function and you'll obtain a csv file with all the extracted data\n",
    "df_to_csv(df_tot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nicolas-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
